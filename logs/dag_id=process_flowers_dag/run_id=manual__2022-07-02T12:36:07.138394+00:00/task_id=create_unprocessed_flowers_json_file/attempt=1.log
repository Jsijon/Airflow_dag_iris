[2022-07-02 12:36:09,440] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: process_flowers_dag.create_unprocessed_flowers_json_file manual__2022-07-02T12:36:07.138394+00:00 [queued]>
[2022-07-02 12:36:09,459] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: process_flowers_dag.create_unprocessed_flowers_json_file manual__2022-07-02T12:36:07.138394+00:00 [queued]>
[2022-07-02 12:36:09,459] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-07-02 12:36:09,459] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-07-02 12:36:09,459] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-07-02 12:36:09,498] {taskinstance.py:1378} INFO - Executing <Task(_PythonDecoratedOperator): create_unprocessed_flowers_json_file> on 2022-07-02 12:36:07.138394+00:00
[2022-07-02 12:36:09,507] {standard_task_runner.py:52} INFO - Started process 362 to run task
[2022-07-02 12:36:09,512] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'process_flowers_dag', 'create_unprocessed_flowers_json_file', 'manual__2022-07-02T12:36:07.138394+00:00', '--job-id', '60', '--raw', '--subdir', 'DAGS_FOLDER/process_iris_data.py', '--cfg-path', '/tmp/tmpzsqjqkfw', '--error-file', '/tmp/tmpwnocn3uj']
[2022-07-02 12:36:09,513] {standard_task_runner.py:80} INFO - Job 60: Subtask create_unprocessed_flowers_json_file
[2022-07-02 12:36:09,604] {task_command.py:370} INFO - Running <TaskInstance: process_flowers_dag.create_unprocessed_flowers_json_file manual__2022-07-02T12:36:07.138394+00:00 [running]> on host a5e5aec483b5
[2022-07-02 12:36:09,735] {taskinstance.py:1572} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=process_flowers_dag
AIRFLOW_CTX_TASK_ID=create_unprocessed_flowers_json_file
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T12:36:07.138394+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-07-02T12:36:07.138394+00:00
[2022-07-02 12:36:09,760] {python.py:173} INFO - Done. Returned value was:      sepal.length  sepal.width  ...  petal_length  petal_width
0             5.1          3.5  ...           NaN          NaN
1             4.9          3.0  ...           NaN          NaN
2             4.7          3.2  ...           NaN          NaN
3             4.6          3.1  ...           NaN          NaN
4             5.0          3.6  ...           NaN          NaN
..            ...          ...  ...           ...          ...
148           6.2          3.4  ...           NaN          NaN
149           5.9          3.0  ...           NaN          NaN
150           NaN          NaN  ...           1.4          0.2
151           NaN          NaN  ...           1.4          0.2
152           NaN          NaN  ...           1.3          0.2

[153 rows x 10 columns]
[2022-07-02 12:36:09,816] {xcom.py:585} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config.
[2022-07-02 12:36:09,816] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2395, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 197, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 582, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/local/lib/python3.7/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2022-07-02 12:36:09,834] {taskinstance.py:1401} INFO - Marking task as FAILED. dag_id=process_flowers_dag, task_id=create_unprocessed_flowers_json_file, execution_date=20220702T123607, start_date=20220702T123609, end_date=20220702T123609
[2022-07-02 12:36:09,856] {standard_task_runner.py:97} ERROR - Failed to execute job 60 for task create_unprocessed_flowers_json_file (Object of type DataFrame is not JSON serializable; 362)
[2022-07-02 12:36:09,895] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-07-02 12:36:09,972] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
