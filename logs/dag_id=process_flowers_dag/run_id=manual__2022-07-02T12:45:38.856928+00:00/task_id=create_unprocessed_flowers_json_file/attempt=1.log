[2022-07-02 12:45:42,327] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: process_flowers_dag.create_unprocessed_flowers_json_file manual__2022-07-02T12:45:38.856928+00:00 [queued]>
[2022-07-02 12:45:42,348] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: process_flowers_dag.create_unprocessed_flowers_json_file manual__2022-07-02T12:45:38.856928+00:00 [queued]>
[2022-07-02 12:45:42,348] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-07-02 12:45:42,348] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-07-02 12:45:42,348] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-07-02 12:45:42,381] {taskinstance.py:1378} INFO - Executing <Task(_PythonDecoratedOperator): create_unprocessed_flowers_json_file> on 2022-07-02 12:45:38.856928+00:00
[2022-07-02 12:45:42,389] {standard_task_runner.py:52} INFO - Started process 197 to run task
[2022-07-02 12:45:42,396] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'process_flowers_dag', 'create_unprocessed_flowers_json_file', 'manual__2022-07-02T12:45:38.856928+00:00', '--job-id', '72', '--raw', '--subdir', 'DAGS_FOLDER/process_iris_data.py', '--cfg-path', '/tmp/tmp3phrofmx', '--error-file', '/tmp/tmpmcpk2cgy']
[2022-07-02 12:45:42,397] {standard_task_runner.py:80} INFO - Job 72: Subtask create_unprocessed_flowers_json_file
[2022-07-02 12:45:42,530] {task_command.py:370} INFO - Running <TaskInstance: process_flowers_dag.create_unprocessed_flowers_json_file manual__2022-07-02T12:45:38.856928+00:00 [running]> on host a5e5aec483b5
[2022-07-02 12:45:42,680] {taskinstance.py:1572} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=process_flowers_dag
AIRFLOW_CTX_TASK_ID=create_unprocessed_flowers_json_file
AIRFLOW_CTX_EXECUTION_DATE=2022-07-02T12:45:38.856928+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-07-02T12:45:38.856928+00:00
[2022-07-02 12:45:42,711] {python.py:173} INFO - Done. Returned value was:      5.1  3.5  1.4   .2  ... sepal_width  petal_length petal_width variety
0    4.9  3.0  1.4  0.2  ...         NaN           NaN         NaN     NaN
1    4.7  3.2  1.3  0.2  ...         NaN           NaN         NaN     NaN
2    4.6  3.1  1.5  0.2  ...         NaN           NaN         NaN     NaN
3    5.0  3.6  1.4  0.2  ...         NaN           NaN         NaN     NaN
4    5.4  3.9  1.7  0.4  ...         NaN           NaN         NaN     NaN
..   ...  ...  ...  ...  ...         ...           ...         ...     ...
147  6.2  3.4  5.4  2.3  ...         NaN           NaN         NaN     NaN
148  5.9  3.0  5.1  1.8  ...         NaN           NaN         NaN     NaN
149  NaN  NaN  NaN  NaN  ...         3.5           1.4         0.2  Setosa
150  NaN  NaN  NaN  NaN  ...           3           1.4         0.2  Setosa
151  NaN  NaN  NaN  NaN  ...         3.2           1.3         0.2  Setosa

[152 rows x 11 columns]
[2022-07-02 12:45:42,762] {xcom.py:585} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config.
[2022-07-02 12:45:42,763] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2395, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 197, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 582, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/local/lib/python3.7/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2022-07-02 12:45:42,777] {taskinstance.py:1401} INFO - Marking task as FAILED. dag_id=process_flowers_dag, task_id=create_unprocessed_flowers_json_file, execution_date=20220702T124538, start_date=20220702T124542, end_date=20220702T124542
[2022-07-02 12:45:42,797] {standard_task_runner.py:97} ERROR - Failed to execute job 72 for task create_unprocessed_flowers_json_file (Object of type DataFrame is not JSON serializable; 197)
[2022-07-02 12:45:42,849] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-07-02 12:45:42,935] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
